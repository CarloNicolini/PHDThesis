%\begin{table}[htb!]
%\noindent\begin{tabular}{@{}*{4}{p{\textwidth}@{}}}
\begin{longtable}{@{}*{3}{p{\textwidth}@{}}}
$V$ \quad {\color{gray!50}\hrulefill} \quad  A set of $n$ vertices (or nodes) \\
$E$ \quad {\color{gray!50}\hrulefill} \quad  A set of $m$ edges (or links) \\
$G=(V,E)$ \quad {\color{gray!50}\hrulefill} \quad  A graph with its vertices and edges \\
$n$ \quad {\color{gray!50}\hrulefill} \quad  The number of nodes in $G$ \\
$m$ \quad {\color{gray!50}\hrulefill} \quad  The number of edges in $G$ \\
%$p$ \quad {\color{gray!50}\hrulefill} \quad  number of vertex pairs $p=\binom{n}{2}$\\
$\mathbf{A}$ \quad {\color{gray!50}\hrulefill} \quad  Adjacency matrix of a graph \\
$\mathbf{W}$ \quad {\color{gray!50}\hrulefill} \quad  Weighted adjacency matrix of a graph \\
$C_n$ \quad {\color{gray!50}\hrulefill} \quad  Cycle graph with $n$ vertices \\
$K_n$ \quad {\color{gray!50}\hrulefill} \quad  Clique or complete graph with $n$ vertices \\
$\mathbf{H}(\sigma)$ \quad {\color{gray!50}\hrulefill} \quad  Hamiltonian (energy) of a partition \\
$\mathbf{I}$ \quad {\color{gray!50}\hrulefill} \quad  Identity matrix \\
$\mathbf{L}$ \quad {\color{gray!50}\hrulefill} \quad  Laplacian matrix of a graph \\
$\Pr(\cdot)$ \quad {\color{gray!50}\hrulefill} \quad  Probability distribution \\
$\mathcal{Q}^N$ \quad {\color{gray!50}\hrulefill} \quad  Modularity function \\
$S$ \quad {\color{gray!50}\hrulefill} \quad  Surprise function \\
$\mathcal{S}_a$ \quad {\color{gray!50}\hrulefill} \quad  Asymptotical Surprise function \\
$\delta(i,j)$ \quad {\color{gray!50}\hrulefill} \quad  Kronecker delta \\
$\left<\cdot \right>$ \quad {\color{gray!50}\hrulefill} \quad  Expected (average value) \\
$P_{ij}$ \quad {\color{gray!50}\hrulefill} \quad  Null model \\
$\| \cdot \|_F$ \quad {\color{gray!50}\hrulefill} \quad  Frobenius norm \\
$\sigma$ \quad {\color{gray!50}\hrulefill} \quad  Partition (membership)\\
$\sigma_i$ \quad {\color{gray!50}\hrulefill} \quad  Community index of vertex $i$ \\
$\mathbf{1}$ \quad {\color{gray!50}\hrulefill} \quad  Vector of all $1$ \\
$k,k^{\textrm{out}},k^{\textrm{in}}$ \quad {\color{gray!50}\hrulefill} \quad  undirected, outgoing and incoming degree \\
$k^{\textrm{int}},k^{\textrm{ext}}$ \quad {\color{gray!50}\hrulefill} \quad  internal and external degree \\
$s,s^{\textrm{out}},s^{\textrm{in}}$ \quad {\color{gray!50}\hrulefill} \quad  undirected, outgoing and incoming strength \\
$s^{\textrm{int}},s^{\textrm{ext}}$ \quad {\color{gray!50}\hrulefill} \quad  internal and external strength \\
$\Gamma(u)$ \quad {\color{gray!50}\hrulefill} \quad  Neighboring vertices of vertex $u$
\end{longtable}
%\end{tabular}
%\end{table}

\section*{Acronyms}
In this paragraph we introduce the acronyms used in the rest of this thesis.

\begin{longtable}{@{}*{4}{p{\textwidth}@{}}}
BOLD \quad {\color{gray!50}\hrulefill} \quad  Blood Oxygen Level Dependent \\
CNM \quad {\color{gray!50}\hrulefill} \quad  Clauset-Newman-Moore \\
CPM \quad {\color{gray!50}\hrulefill} \quad  Constant Potts Model \\
ER \quad {\color{gray!50}\hrulefill} \quad  Erdos-Renyi \\
FC \quad {\color{gray!50}\hrulefill} \quad  Functional Connectivity \\
LFR \quad {\color{gray!50}\hrulefill} \quad  Lancichinetti-Fortunato-Radicchi model \\
LM \quad {\color{gray!50}\hrulefill} \quad  Louvain method \\
MOD \quad {\color{gray!50}\hrulefill} \quad  Modularity \\
fMRI \quad {\color{gray!50}\hrulefill} \quad  Functional Magnetic Resonance Imaging \\
RB \quad {\color{gray!50}\hrulefill} \quad  Reichardt-Bornholdt \\
TMS \quad {\color{gray!50}\hrulefill} \quad  Transcranial magnetic stimulation \\
EEG \quad {\color{gray!50}\hrulefill} \quad  Electroencefalography \\
WCC \quad {\color{gray!50}\hrulefill} \quad  Weakly connected component \\
PACO \quad {\color{gray!50}\hrulefill} \quad  PArtitioning Cost Optimization \\
FAGSO \quad {\color{gray!50}\hrulefill} \quad  Fast Agglomerative Surprise Optimization \\
SA \quad {\color{gray!50}\hrulefill} \quad  Simulated Annealing 
\end{longtable}

\section*{Information theory}
%\begin{table}
%\noindent\begin{tabular}{@{}*{4}{p{\textwidth}@{}}}
\begin{longtable}{@{}*{4}{p{\textwidth}@{}}}
$H(X)$ \quad {\color{gray!50}\hrulefill} \quad  Shannon Entropy of $X$ \\
$H(X,Y)$ \quad {\color{gray!50}\hrulefill} \quad  Joint Entropy \\
$H(X|Y)$ \quad {\color{gray!50}\hrulefill} \quad  Conditional Entropy \\
$I(x)$ \quad {\color{gray!50}\hrulefill} \quad  Information of event $x$ \\
$I(X,Y)$ \quad {\color{gray!50}\hrulefill} \quad  Mutual information \\
$NMI(X,Y)$ \quad {\color{gray!50}\hrulefill} \quad  Normalized Mutual Information \\
$rNMI(X,Y)$ \quad {\color{gray!50}\hrulefill} \quad  Relative Normalized Mutual Information \\
$\Pr(x)$ \quad {\color{gray!50}\hrulefill} \quad  Probability to observe $x$ \\
$\Pr(x,y)$ \quad {\color{gray!50}\hrulefill} \quad  Joint probability \\
$\Pr(x|y)$ \quad {\color{gray!50}\hrulefill} \quad  Conditional probability
%\end{tabular}
%\end{table}
\end{longtable}